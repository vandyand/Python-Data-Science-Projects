{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')\n",
    "\n",
    "holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load functions.py\n",
    "def process_missing(df):\n",
    "    \"\"\"Handle various missing values from the data set\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    holdout = process_missing(holdout)\n",
    "    \"\"\"\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    return df\n",
    "\n",
    "def process_age(df):\n",
    "    \"\"\"Process the Age column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_age(train)\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_fare(df):\n",
    "    \"\"\"Process the Fare column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_fare(train)\n",
    "    \"\"\"\n",
    "    cut_points = [-1,12,50,100,1000]\n",
    "    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_cabin(df):\n",
    "    \"\"\"Process the Cabin column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train process_cabin(train)\n",
    "    \"\"\"\n",
    "    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "    df.loc[df['Cabin_type']=='T','Cabin_type'] = 'Unknown'\n",
    "    df = df.drop('Cabin',axis=1)\n",
    "    return df\n",
    "\n",
    "def process_titles(df):\n",
    "    \"\"\"Extract and categorize the title from the name column \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_titles(train)\n",
    "    \"\"\"\n",
    "    titles = {\n",
    "        \"Mr\" :         \"Mr\",\n",
    "        \"Mme\":         \"Mrs\",\n",
    "        \"Ms\":          \"Mrs\",\n",
    "        \"Mrs\" :        \"Mrs\",\n",
    "        \"Master\" :     \"Master\",\n",
    "        \"Mlle\":        \"Miss\",\n",
    "        \"Miss\" :       \"Miss\",\n",
    "        \"Capt\":        \"Officer\",\n",
    "        \"Col\":         \"Officer\",\n",
    "        \"Major\":       \"Officer\",\n",
    "        \"Dr\":          \"Officer\",\n",
    "        \"Rev\":         \"Officer\",\n",
    "        \"Jonkheer\":    \"Royalty\",\n",
    "        \"Don\":         \"Royalty\",\n",
    "        \"Sir\" :        \"Royalty\",\n",
    "        \"Countess\":    \"Royalty\",\n",
    "        \"Dona\":        \"Royalty\",\n",
    "        \"Lady\" :       \"Royalty\"\n",
    "    }\n",
    "    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    df[\"Title\"] = extracted_titles.map(titles)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = create_dummies(train,\"Age\")\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    df = process_missing(df)\n",
    "    df = process_age(df)\n",
    "    df = process_fare(df)\n",
    "    df = process_cabin(df)\n",
    "    df = process_titles(df)\n",
    "    df = create_dummies(df,['Age_categories','Fare_categories','Title','Cabin_type','Sex'])\n",
    "    return df\n",
    "\n",
    "train = prep_data(train)\n",
    "holdout = prep_data(holdout)\n",
    "holdout['Cabin_type_T'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isalone(df):\n",
    "    df['family_size'] = df[['SibSp','Parch']].sum(axis=1)\n",
    "    df['isalone'] = 0\n",
    "    df.loc[(df.family_size==0),'isalone']=1\n",
    "    df.loc[:,'family_size'] = (df.family_size - df.family_size.min())/(df.family_size.max() - df.family_size.min())\n",
    "    return df\n",
    "\n",
    "train = isalone(train)\n",
    "holdout = isalone(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      int64\n",
       "Survived                         int64\n",
       "Pclass                           int64\n",
       "Name                            object\n",
       "Sex                             object\n",
       "Age                            float64\n",
       "SibSp                            int64\n",
       "Parch                            int64\n",
       "Ticket                          object\n",
       "Fare                           float64\n",
       "Embarked                        object\n",
       "Age_categories                category\n",
       "Fare_categories               category\n",
       "Cabin_type                      object\n",
       "Title                           object\n",
       "Age_categories_Missing           uint8\n",
       "Age_categories_Infant            uint8\n",
       "Age_categories_Child             uint8\n",
       "Age_categories_Teenager          uint8\n",
       "Age_categories_Young Adult       uint8\n",
       "Age_categories_Adult             uint8\n",
       "Age_categories_Senior            uint8\n",
       "Fare_categories_0-12             uint8\n",
       "Fare_categories_12-50            uint8\n",
       "Fare_categories_50-100           uint8\n",
       "Fare_categories_100+             uint8\n",
       "Title_Master                     uint8\n",
       "Title_Miss                       uint8\n",
       "Title_Mr                         uint8\n",
       "Title_Mrs                        uint8\n",
       "Title_Officer                    uint8\n",
       "Title_Royalty                    uint8\n",
       "Cabin_type_A                     uint8\n",
       "Cabin_type_B                     uint8\n",
       "Cabin_type_C                     uint8\n",
       "Cabin_type_D                     uint8\n",
       "Cabin_type_E                     uint8\n",
       "Cabin_type_F                     uint8\n",
       "Cabin_type_G                     uint8\n",
       "Cabin_type_Unknown               uint8\n",
       "Sex_female                       uint8\n",
       "Sex_male                         uint8\n",
       "family_size                    float64\n",
       "isalone                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "------------------\n",
      "Best Score: 0.819304152637486\n",
      "Best Parameters: {'solver': 'lbfgs'}\n",
      "\n",
      "KNeighborsClassifier\n",
      "--------------------\n",
      "Best Score: 0.7755331088664422\n",
      "Best Parameters: {'algorithm': 'kd_tree', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "RandomForestClassifier\n",
      "----------------------\n",
      "Best Score: 0.8395061728395061\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9}\n",
      "\n",
      "SVC\n",
      "---\n",
      "Best Score: 0.8294051627384961\n",
      "Best Parameters: {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "\n",
      "BernoulliNB\n",
      "-----------\n",
      "Best Score: 0.7856341189674523\n",
      "Best Parameters: {'alpha': 0.0, 'binarize': 0.5}\n",
      "\n",
      "GradientBoostingClassifier\n",
      "--------------------------\n",
      "Best Score: 0.835016835016835\n",
      "Best Parameters: {'max_depth': 5, 'n_estimators': 50}\n",
      "\n",
      "AdaBoostClassifier\n",
      "------------------\n",
      "Best Score: 0.8282828282828283\n",
      "Best Parameters: {'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "\n",
    "def select_model(df):\n",
    "    \n",
    "    list_of_dicts = [\n",
    "        {'name':'LogisticRegression',\n",
    "         'estimator':LogisticRegression(),\n",
    "         'hyperparameters':{\n",
    "             'solver':['newton-cg','lbfgs','liblinear']\n",
    "         }\n",
    "        },\n",
    "        {'name':'KNeighborsClassifier',\n",
    "         'estimator':KNeighborsClassifier(),\n",
    "         'hyperparameters':{\n",
    "             'n_neighbors': range(1,20,2),\n",
    "             'weights': ['distance','uniform'],\n",
    "             'algorithm': ['ball_tree','kd_tree','brute'],\n",
    "             'p': [1,2]\n",
    "         }\n",
    "        },\n",
    "        {'name':'RandomForestClassifier',\n",
    "         'estimator':RandomForestClassifier(),\n",
    "         'hyperparameters':{\n",
    "             'n_estimators': [4,6,9],\n",
    "             'criterion': ['entropy', 'gini'],\n",
    "             'max_depth': [2,5,10],\n",
    "             'max_features': ['log2','sqrt'],\n",
    "             'min_samples_leaf': [1,5,8],\n",
    "             'min_samples_split': [2,3,5]\n",
    "         }\n",
    "        },\n",
    "        {'name':'SVC',\n",
    "         'estimator':SVC(),\n",
    "         'hyperparameters':{\n",
    "             'C': [1,10,100,1000,10000],\n",
    "             'kernel': ['rbf'],\n",
    "             'gamma': [0.00001,0.0001,0.001,0.01,0.1]\n",
    "              }\n",
    "          },\n",
    "         {'name':'BernoulliNB',\n",
    "         'estimator':BernoulliNB(),\n",
    "         'hyperparameters':{\n",
    "            'alpha': np.linspace(0,0.1,101),\n",
    "            'binarize': [0.5]\n",
    "             }\n",
    "         },\n",
    "         {'name':'GradientBoostingClassifier',\n",
    "          'estimator':GradientBoostingClassifier(),\n",
    "          'hyperparameters':{\n",
    "             'n_estimators':[20,50,100,500],\n",
    "             'max_depth':[1,3,5,10]\n",
    "             }\n",
    "         },\n",
    "         {'name':'AdaBoostClassifier',\n",
    "          'estimator':AdaBoostClassifier(),\n",
    "          'hyperparameters':{'n_estimators':[25,50,100,200]}\n",
    "         }\n",
    "    ]\n",
    "    \n",
    "    all_y = df.Survived\n",
    "    \n",
    "    for dictt in list_of_dicts:\n",
    "        df = df.select_dtypes([np.number]).dropna(axis=1)\n",
    "        all_X = df.drop(['PassengerId','Survived'],axis=1)\n",
    "        dictt['best_features'] = list(all_X.columns)\n",
    "        print(dictt['name'])\n",
    "        print('-'*len(dictt['name']))\n",
    "        grid = GridSearchCV(dictt['estimator'],param_grid=dictt['hyperparameters'],cv=10)\n",
    "        grid.fit(all_X,all_y)\n",
    "        dictt['best_params'] = grid.best_params_\n",
    "        dictt['best_score'] = grid.best_score_\n",
    "        dictt['best_model'] = grid.best_estimator_\n",
    "        print(\"Best Score: {}\".format(dictt[\"best_score\"]))\n",
    "        print(\"Best Parameters: {}\\n\".format(dictt[\"best_params\"]))\n",
    "    return list_of_dicts\n",
    "\n",
    "optimized_models = select_model(train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_submission_file(model,best_features,\n",
    "                         filename='submission.csv'):\n",
    "    holdout_predictions = model.predict(holdout[best_features])\n",
    "    submission = pd.DataFrame({'PassengerId':holdout.PassengerId,\n",
    "                               'Survived':holdout_predictions})\n",
    "    submission.to_csv(filename,index=False)\n",
    "\n",
    "model = optimized_models[5]['best_model']\n",
    "best_features = optimized_models[5]['best_features']\n",
    "save_submission_file(model,best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest gave the best accuracy of 79.4% on kaggle.com.\n",
    "\n",
    "SVC gave a score of 78.5%.\n",
    "\n",
    "Surprisingly, Gradient Boosting only yielded 76.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Majority Vote of Random Forest, SVC and Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('rfc', optimized_models[2]['best_model']),\n",
    "                                    ('svc', optimized_models[3]['best_model']),\n",
    "                                    ('gbc', optimized_models[5]['best_model'])], voting='hard')\n",
    "eclf.fit(train.select_dtypes([np.number]).dropna(axis=1).drop(['PassengerId','Survived'],axis=1),train.Survived)\n",
    "best_features = optimized_models[5]['best_features']\n",
    "save_submission_file(eclf,best_features,'submission_voting.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority vote yielded a score of 78.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
